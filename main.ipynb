{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the requirements\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading bank data into pandas dataframe\n",
    "bank_data = arff.loadarff('Datasets/bank-additional-ful-nominal.arff')\n",
    "bank_data_df= pd.DataFrame(bank_data[0])\n",
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading census data into pandas dataframe\n",
    "census_data = arff.loadarff('Datasets/census-income-full-nominal.arff')\n",
    "census_data_df= pd.DataFrame(census_data[0])\n",
    "census_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the datatype of the elements in the given data\n",
    "print(type(bank_data[0][0][0]))\n",
    "print(type(census_data[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the numpy bytes to strings in bank data\n",
    "bank_data_df = bank_data_df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the numpy bytes to strings in census data\n",
    "census_data_df = census_data_df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "census_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the name and data in the last column of bank data\n",
    "bank_data_df.rename(columns={'y':'anamoly'}, inplace=True)\n",
    "bank_data_df['anamoly'] = bank_data_df['anamoly'].map({'no':0,'yes':1})\n",
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the name and data in the last column of census data\n",
    "census_data_df.rename(columns={'class':'anamoly'}, inplace=True)\n",
    "census_data_df['anamoly'] = census_data_df['anamoly'].map({'50000+.':1,'--50000.':0})\n",
    "census_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature encoding of bank data using target encoding\n",
    "target_encoder = ce.TargetEncoder(cols=bank_data_df.columns[:-1])\n",
    "bank_data_df[bank_data_df.columns[:-1]] = target_encoder.fit_transform(bank_data_df[bank_data_df.columns[:-1]], bank_data_df['anamoly'])\n",
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of the bank data and if there any null values in the data\n",
    "print(bank_data_df.shape)\n",
    "print(bank_data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of the census data and if there any null values in the data\n",
    "print(census_data_df.shape)\n",
    "print(census_data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the bank data\n",
    "excluded_column = bank_data_df['anamoly']\n",
    "columns_to_scale = bank_data_df.drop(columns = ['anamoly'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(columns_to_scale)\n",
    "bank_data_df = pd.DataFrame(scaled_data, columns=columns_to_scale.columns, index = bank_data_df.index)\n",
    "bank_data_df['anamoly'] = excluded_column\n",
    "\n",
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = bank_data_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "\n",
    "high_corr_pairs = np.where(np.abs(corr_matrix) > 0.8)\n",
    "high_corr_pairs = [(corr_matrix.index[x], corr_matrix.columns[y]) for x, y in zip(*high_corr_pairs) if x != y and x < y]\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bank_data_df.iloc[:, :-1]\n",
    "y = bank_data_df.iloc[:, -1]  \n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "tsne_df = pd.DataFrame(X_tsne, columns=['TSNE1', 'TSNE2'])\n",
    "tsne_df['Target'] = y\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=tsne_df, x=\"TSNE1\", y=\"TSNE2\", hue=\"Target\", palette=\"coolwarm\")\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"Isolation Forest\": IsolationForest(contamination=0.1, random_state=42),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(n_neighbors=20, contamination=0.1, novelty=True),\n",
    "    \"Elliptic Envelope\": EllipticEnvelope(contamination=0.1, random_state=42),\n",
    "    \"DBSCAN\": DBSCAN(eps=0.3, min_samples=10),\n",
    "    \"One-Class SVM\": OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "}\n",
    "\n",
    "for name, model in methods.items():\n",
    "    if name == \"Local Outlier Factor\":\n",
    "        model.fit(X_tsne)  \n",
    "        predictions = model.predict(X_tsne)\n",
    "    elif name == \"DBSCAN\":\n",
    "        predictions = model.fit_predict(X_tsne)\n",
    "    else:\n",
    "        model.fit(X_tsne)\n",
    "        predictions = model.predict(X_tsne)\n",
    "\n",
    "    anomaly_labels = (predictions == -1).astype(int)\n",
    "\n",
    "    tsne_df['Anomaly_Predicted'] = anomaly_labels\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=tsne_df, x=\"TSNE1\", y=\"TSNE2\", hue=\"Anomaly_Predicted\", palette=\"coolwarm\", legend=\"full\")\n",
    "    plt.title(f\"{name} Anomaly Detection on t-SNE Reduced Data\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
